package llm

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"strings"
	"time"

	"github.com/AlexGladkov/guardian-cli/internal/config"
)

// apiKeyEnvVar is the environment variable name for the LLM API key.
const apiKeyEnvVar = "GUARDIAN_LLM_API_KEY"

// Client is the LLM client that communicates with a configured provider.
type Client struct {
	provider   string
	endpoint   string
	model      string
	apiKey     string
	prompts    config.LLMPrompts
	httpClient *http.Client
}

// Violation represents a rule violation found by the engine.
// It is defined here to avoid circular imports with the engine package.
type Violation struct {
	RuleID      string
	Severity    string
	Description string
	FilePath    string
	DiffSnippet string
}

// CheckAnalysis represents the LLM response for a check analysis.
type CheckAnalysis struct {
	Explanations map[string]string // rule_id -> explanation
}

// ProposalDraft represents a draft proposal generated by the LLM.
type ProposalDraft struct {
	ChangeDescription string
	ChangeDetails     string
	Reason            string
	Impact            string
}

// openAI-compatible request/response types.
type openAIRequest struct {
	Model    string          `json:"model"`
	Messages []openAIMessage `json:"messages"`
}

type openAIMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type openAIResponse struct {
	Choices []struct {
		Message openAIMessage `json:"message"`
	} `json:"choices"`
	Error *struct {
		Message string `json:"message"`
	} `json:"error"`
}

// Claude (Anthropic Messages API) request/response types.
type claudeRequest struct {
	Model     string          `json:"model"`
	MaxTokens int             `json:"max_tokens"`
	Messages  []claudeMessage `json:"messages"`
	System    string          `json:"system,omitempty"`
}

type claudeMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type claudeResponse struct {
	Content []struct {
		Text string `json:"text"`
	} `json:"content"`
	Error *struct {
		Message string `json:"message"`
	} `json:"error"`
}

// NewClient creates a new LLM client from constitution config.
// It reads the API key from the GUARDIAN_LLM_API_KEY environment variable.
// Returns an error if the API key is not set.
func NewClient(cfg config.LLMConfig) (*Client, error) {
	apiKey := os.Getenv(apiKeyEnvVar)
	if apiKey == "" {
		return nil, fmt.Errorf("environment variable %s is not set; configure it with your LLM API key", apiKeyEnvVar)
	}

	provider := cfg.Provider
	if provider == "" {
		provider = ProviderDeepSeek
	}

	endpoint := cfg.Endpoint
	if endpoint == "" {
		if ep, ok := ProviderEndpoints[provider]; ok {
			endpoint = ep
		} else {
			return nil, fmt.Errorf("no endpoint configured for provider %q; set llm.endpoint in constitution.yml", provider)
		}
	}

	model := cfg.Model
	if model == "" {
		if m, ok := DefaultModels[provider]; ok {
			model = m
		} else {
			model = "default"
		}
	}

	return &Client{
		provider: provider,
		endpoint: endpoint,
		model:    model,
		apiKey:   apiKey,
		prompts:  cfg.Prompts,
		httpClient: &http.Client{
			Timeout: 30 * time.Second,
		},
	}, nil
}

// AnalyzeCheck sends diff content and violations to the LLM for analysis.
// It returns explanations keyed by rule ID.
func (c *Client) AnalyzeCheck(diffContent string, rules []config.Rule, violations []Violation) (*CheckAnalysis, error) {
	systemPrompt := GetCheckPrompt(c.prompts.CheckSystem)

	var userContent strings.Builder
	userContent.WriteString("## Git Diff\n```\n")
	userContent.WriteString(diffContent)
	userContent.WriteString("\n```\n\n")

	userContent.WriteString("## Team Rules\n")
	for _, r := range rules {
		fmt.Fprintf(&userContent, "- **%s** (%s): %s\n", r.ID, r.Severity, r.Description)
	}
	userContent.WriteString("\n")

	userContent.WriteString("## Detected Violations\n")
	for _, v := range violations {
		fmt.Fprintf(&userContent, "### %s [%s]\n", v.RuleID, v.Severity)
		fmt.Fprintf(&userContent, "- Description: %s\n", v.Description)
		fmt.Fprintf(&userContent, "- File: %s\n", v.FilePath)
		if v.DiffSnippet != "" {
			fmt.Fprintf(&userContent, "- Diff snippet:\n```\n%s\n```\n", v.DiffSnippet)
		}
		userContent.WriteString("\n")
	}

	userContent.WriteString("Please provide a brief explanation for each violation, keyed by rule_id. ")
	userContent.WriteString("Format your response as one paragraph per violation, starting each with the rule_id in brackets like [rule_id].")

	responseText, err := c.sendMessage(systemPrompt, userContent.String())
	if err != nil {
		return nil, fmt.Errorf("LLM analysis failed: %w", err)
	}

	explanations := parseExplanations(responseText, violations)
	return &CheckAnalysis{Explanations: explanations}, nil
}

// DraftProposal generates a proposal draft using the LLM.
func (c *Client) DraftProposal(rule config.Rule, context string) (*ProposalDraft, error) {
	systemPrompt := GetProposePrompt(c.prompts.ProposeSystem)

	var userContent strings.Builder
	fmt.Fprintf(&userContent, "## Rule\n- ID: %s\n- Description: %s\n- Type: %s\n- Severity: %s\n\n",
		rule.ID, rule.Description, rule.Type, rule.Severity)

	if context != "" {
		fmt.Fprintf(&userContent, "## Context\n%s\n\n", context)
	}

	userContent.WriteString("Please generate a proposal with the following sections:\n")
	userContent.WriteString("CHANGE_DESCRIPTION: (one line summary)\n")
	userContent.WriteString("CHANGE_DETAILS: (detailed description)\n")
	userContent.WriteString("REASON: (why this change is needed)\n")
	userContent.WriteString("IMPACT: (expected impact)\n")

	responseText, err := c.sendMessage(systemPrompt, userContent.String())
	if err != nil {
		return nil, fmt.Errorf("LLM proposal draft failed: %w", err)
	}

	draft := parseProposalDraft(responseText)
	return draft, nil
}

// sendMessage sends a message to the configured LLM provider and returns the response text.
func (c *Client) sendMessage(systemPrompt, userMessage string) (string, error) {
	if c.provider == ProviderClaude {
		return c.sendClaudeMessage(systemPrompt, userMessage)
	}
	return c.sendOpenAIMessage(systemPrompt, userMessage)
}

// sendOpenAIMessage sends a message using the OpenAI-compatible API format.
// This works for deepseek, openai, and custom providers.
func (c *Client) sendOpenAIMessage(systemPrompt, userMessage string) (string, error) {
	reqBody := openAIRequest{
		Model: c.model,
		Messages: []openAIMessage{
			{Role: "system", Content: systemPrompt},
			{Role: "user", Content: userMessage},
		},
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return "", fmt.Errorf("marshaling request: %w", err)
	}

	url := strings.TrimRight(c.endpoint, "/") + "/chat/completions"
	req, err := http.NewRequest(http.MethodPost, url, bytes.NewReader(jsonData))
	if err != nil {
		return "", fmt.Errorf("creating request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+c.apiKey)

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("sending request to %s: %w", url, err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("reading response body: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("LLM API returned status %d: %s", resp.StatusCode, string(body))
	}

	var apiResp openAIResponse
	if err := json.Unmarshal(body, &apiResp); err != nil {
		return "", fmt.Errorf("parsing response JSON: %w", err)
	}

	if apiResp.Error != nil {
		return "", fmt.Errorf("LLM API error: %s", apiResp.Error.Message)
	}

	if len(apiResp.Choices) == 0 {
		return "", fmt.Errorf("LLM API returned no choices")
	}

	return apiResp.Choices[0].Message.Content, nil
}

// sendClaudeMessage sends a message using the Anthropic Messages API format.
func (c *Client) sendClaudeMessage(systemPrompt, userMessage string) (string, error) {
	reqBody := claudeRequest{
		Model:     c.model,
		MaxTokens: 4096,
		Messages: []claudeMessage{
			{Role: "user", Content: userMessage},
		},
		System: systemPrompt,
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return "", fmt.Errorf("marshaling request: %w", err)
	}

	url := strings.TrimRight(c.endpoint, "/") + "/messages"
	req, err := http.NewRequest(http.MethodPost, url, bytes.NewReader(jsonData))
	if err != nil {
		return "", fmt.Errorf("creating request: %w", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("x-api-key", c.apiKey)
	req.Header.Set("anthropic-version", "2023-06-01")

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return "", fmt.Errorf("sending request to %s: %w", url, err)
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", fmt.Errorf("reading response body: %w", err)
	}

	if resp.StatusCode != http.StatusOK {
		return "", fmt.Errorf("LLM API returned status %d: %s", resp.StatusCode, string(body))
	}

	var apiResp claudeResponse
	if err := json.Unmarshal(body, &apiResp); err != nil {
		return "", fmt.Errorf("parsing response JSON: %w", err)
	}

	if apiResp.Error != nil {
		return "", fmt.Errorf("LLM API error: %s", apiResp.Error.Message)
	}

	if len(apiResp.Content) == 0 {
		return "", fmt.Errorf("LLM API returned no content")
	}

	return apiResp.Content[0].Text, nil
}

// parseExplanations extracts per-rule explanations from the LLM response text.
// It looks for [rule_id] prefixes and maps each following text to the rule ID.
// If no structured format is found, the entire response is assigned to each violation's rule ID.
func parseExplanations(responseText string, violations []Violation) map[string]string {
	explanations := make(map[string]string)

	// Collect all rule IDs from violations
	ruleIDs := make(map[string]bool)
	for _, v := range violations {
		ruleIDs[v.RuleID] = true
	}

	// Try to parse [rule_id] sections
	lines := strings.Split(responseText, "\n")
	currentRuleID := ""
	var currentText strings.Builder

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)
		foundRuleID := ""

		// Check if line starts with [rule_id]
		for ruleID := range ruleIDs {
			prefix := "[" + ruleID + "]"
			if strings.HasPrefix(trimmed, prefix) {
				foundRuleID = ruleID
				trimmed = strings.TrimSpace(strings.TrimPrefix(trimmed, prefix))
				break
			}
		}

		if foundRuleID != "" {
			// Save previous section
			if currentRuleID != "" {
				explanations[currentRuleID] = strings.TrimSpace(currentText.String())
			}
			currentRuleID = foundRuleID
			currentText.Reset()
			if trimmed != "" {
				currentText.WriteString(trimmed)
			}
		} else if currentRuleID != "" {
			if currentText.Len() > 0 {
				currentText.WriteString(" ")
			}
			currentText.WriteString(trimmed)
		}
	}

	// Save last section
	if currentRuleID != "" {
		explanations[currentRuleID] = strings.TrimSpace(currentText.String())
	}

	// If no structured explanations were found, assign the entire response to all violations
	if len(explanations) == 0 && len(violations) > 0 {
		text := strings.TrimSpace(responseText)
		for _, v := range violations {
			explanations[v.RuleID] = text
		}
	}

	return explanations
}

// parseProposalDraft extracts proposal sections from the LLM response text.
// It looks for CHANGE_DESCRIPTION:, CHANGE_DETAILS:, REASON:, and IMPACT: markers.
func parseProposalDraft(responseText string) *ProposalDraft {
	draft := &ProposalDraft{}

	sections := map[string]*string{
		"CHANGE_DESCRIPTION:": &draft.ChangeDescription,
		"CHANGE_DETAILS:":     &draft.ChangeDetails,
		"REASON:":             &draft.Reason,
		"IMPACT:":             &draft.Impact,
	}

	// Order of section keys for sequential parsing
	sectionOrder := []string{"CHANGE_DESCRIPTION:", "CHANGE_DETAILS:", "REASON:", "IMPACT:"}

	lines := strings.Split(responseText, "\n")
	currentSection := ""
	var currentText strings.Builder

	for _, line := range lines {
		trimmed := strings.TrimSpace(line)
		foundSection := ""

		for _, key := range sectionOrder {
			upperTrimmed := strings.ToUpper(trimmed)
			if strings.HasPrefix(upperTrimmed, strings.ToUpper(key)) {
				foundSection = key
				trimmed = strings.TrimSpace(trimmed[len(key):])
				break
			}
		}

		if foundSection != "" {
			// Save previous section
			if currentSection != "" {
				if ptr, ok := sections[currentSection]; ok {
					*ptr = strings.TrimSpace(currentText.String())
				}
			}
			currentSection = foundSection
			currentText.Reset()
			if trimmed != "" {
				currentText.WriteString(trimmed)
			}
		} else if currentSection != "" {
			if currentText.Len() > 0 {
				currentText.WriteString("\n")
			}
			currentText.WriteString(trimmed)
		}
	}

	// Save last section
	if currentSection != "" {
		if ptr, ok := sections[currentSection]; ok {
			*ptr = strings.TrimSpace(currentText.String())
		}
	}

	// Fallback: if no sections were parsed, use the entire response as description
	if draft.ChangeDescription == "" && draft.ChangeDetails == "" && draft.Reason == "" && draft.Impact == "" {
		draft.ChangeDescription = strings.TrimSpace(responseText)
	}

	return draft
}
